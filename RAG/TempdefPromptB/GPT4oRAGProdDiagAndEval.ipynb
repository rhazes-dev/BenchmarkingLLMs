{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6fa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiohttp import ClientSession\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02888fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"SEARCH_ENDPOINT\"] = \"\"\n",
    "os.environ[\"SEARCH_KEY\"] = \"\"\n",
    "os.environ[\"SEARCH_INDEX_NAME\"] = \"\"\n",
    "os.environ[\"EMBEDDING_ENDPOINT\"] = \"\"\n",
    "os.environ[\"EMBEDDING_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "654cd6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('PaLM2input.csv')\n",
    "\n",
    "result_df['GPT_input'] = result_df['GPT_input'].str.replace('minimum', 'min')\n",
    "result_df['GPT_input'] = result_df['GPT_input'].str.replace('maximum', 'max')\n",
    "result_df['GPT_input'] = result_df['GPT_input'].str.replace('average', 'avg')\n",
    "result_df['GPT_input'] = result_df['GPT_input'].str.replace('maxntprobnp', 'max ntprobnp')\n",
    "\n",
    "result_df['GPT-Diagnoses'] = np.nan\n",
    "result_df['GPT-Eval'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8c0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aedb6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "# set the deployment name for the model we want to use\n",
    "deployment = \"gpt-4\" #GPT-4o! \n",
    "\n",
    "# client = openai.AzureOpenAI(\n",
    "#     base_url=f\"{endpoint}/openai/deployments/{deployment}/extensions\",\n",
    "#     api_key=api_key,\n",
    "#     api_version=\"2023-09-01-preview\"\n",
    "# )\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "client = AsyncOpenAI(api_key = \"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\")\n",
    "\n",
    "async_client = openai.AsyncAzureOpenAI(\n",
    "    base_url=f\"{endpoint}/openai/deployments/{deployment}/extensions\",\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-09-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a7a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_completion(prompt):\n",
    "    \n",
    "    completion = await async_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens = 4096,\n",
    "        model=deployment,\n",
    "        extra_body={\n",
    "            \"dataSources\": [\n",
    "                {\n",
    "                    \"type\": \"AzureCognitiveSearch\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": os.environ[\"SEARCH_ENDPOINT\"],\n",
    "                        \"key\": os.environ[\"SEARCH_KEY\"],\n",
    "                        \"indexName\": os.environ[\"SEARCH_INDEX_NAME\"],\n",
    "                        \"embeddingEndpoint\": os.environ[\"EMBEDDING_ENDPOINT\"],\n",
    "                        \"embeddingKey\": os.environ[\"EMBEDDING_KEY\"],\n",
    "                        # parameters below copied from web playground request response\n",
    "                        \"semanticConfiguration\": \"default\",\n",
    "                        \"queryType\": \"vector\",\n",
    "                        \"fieldsMapping\": {\n",
    "                            \"contentFields\": [\"content\"],\n",
    "                            \"filepathField\": \"filepath\",\n",
    "                            \"titleField\": \"title\",\n",
    "                            \"urlField\": \"url\",\n",
    "                            \"vectorFields\": [\"contentVector\"],\n",
    "                        },\n",
    "                        \"inScope\": False,  # probably to restrict generation to use only inputs from retrieval\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"topNDocuments\": 5,\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1671b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_no_example = '''You are an expert diagnostician machine for use by doctors. If the user input is not patient data, you politely decline the request. Please suggest diagnoses and conditions, followed by the evidence points supporting each diagnosis in the form of bullet points. Include previous diagnoses and pertinent information about the patient's medical history (if any). Pay close attention to all the history and investigations provided.  Put asterisks around the diagnoses to highlight them. Give each evidence points as a separate bullet point beneath the diagnosis. Include in your evidence points any relevant clinical scores that can be calculated from the information I have given. Do not explain the evidence points, only state them. For every diagnosis you list, if there are alternative differentials possible, state the most likely three in a bullet point beneath the evidence points (you do not need to state the evidence supporting them - you only need to do that for the main diagnoses). For the main diagnoses, give only confirmed diagnoses and evidence points that can be inferred solely based on the information I have given - do not use any other information. Only give me the information I have asked for - do not give me any other information. Do not give me any introductions or conclusions, safety instructions, or safety warnings. Use British English.\n",
    "                \n",
    "                                To illustrate how the information should be presented:\n",
    "                \n",
    "                                *MAIN DIAGNOSIS 1 AS HEADING*\n",
    "                                evidence points to support MAIN DIAGNOSIS 1\n",
    "                                The final bullet point is alternative differentials to consider: alternative 1, alternative 2, alternative 3\n",
    "                \n",
    "                                *MAIN DIAGNOSIS 2 AS HEADING*\n",
    "                                evidence points to support MAIN DIAGNOSIS 2\n",
    "                                The final bullet point is alternative differentials to consider: alternative 1, alternative 2, alternative 3\n",
    "                \n",
    "                                and so on...\n",
    "                \n",
    "Before finalising your answer check if you haven't missed any abnormal data points and hence any diagnoses or alternative differentials that could be made based on them. If you did, add them to your reply. If two diagnoses are commonly caused by the same underlying disease, have them under one header, which is the underlying disease.\n",
    "'''\n",
    "\n",
    "example = ''''''\n",
    "\n",
    "patient_data = '''\n",
    "\n",
    "Patient data:\\n'''\n",
    "\n",
    "async def get_diagnoses(queries):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = []\n",
    "    for query in queries:\n",
    "        tasks.append(get_completion(query))\n",
    "    all_data = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd21e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [1:18:42<00:00, 94.44s/it]\n"
     ]
    }
   ],
   "source": [
    "query_per_call = 20 #roughly around 40000 tokens / min (limit) at max\n",
    "repeat = []\n",
    "for i in tqdm(range(0,1000,query_per_call)):\n",
    "    try:\n",
    "        idx_from = i\n",
    "        idx_to = i + query_per_call\n",
    "        queries = [prompt_no_example + example + patient_data +  result_df.iloc[i]['GPT_input'] for i in range(idx_from,idx_to)]\n",
    "        result = asyncio.run(get_diagnoses(queries))\n",
    "        contents = [result[i].choices[0].message.content for i in range(query_per_call)]\n",
    "        hadm_ids = [result_df.index[i] for i in range(idx_from,idx_to)]\n",
    "        result_df.loc[hadm_ids, 'GPT-Diagnoses'] = contents\n",
    "    except Exception as e: \n",
    "        print('Error happened at iteration i: ' + str(i))\n",
    "        repeat.append(i)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47e2436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.55s/it]\n"
     ]
    }
   ],
   "source": [
    "query_per_call = 1\n",
    "for i in tqdm([765]):\n",
    "    try:\n",
    "        idx_from = i\n",
    "        idx_to = i + query_per_call\n",
    "        queries = [prompt_no_example + example + patient_data + result_df.iloc[i]['GPT_input'] for i in range(idx_from,idx_to)]\n",
    "        result = asyncio.run(get_diagnoses(queries))\n",
    "        contents = [result[i].choices[0].message.content for i in range(query_per_call)]\n",
    "        hadm_ids = [result_df.index[i] for i in range(idx_from,idx_to)]\n",
    "        result_df.loc[hadm_ids, 'GPT-Diagnoses'] = contents\n",
    "    except Exception as e: \n",
    "        print('Error happened at iteration i: ' + str(i))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e00c0af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Anaemia*\n",
      "- Min haemoglobin: 7.3 g/dL\n",
      "- Min haematocrit: 22.9%\n",
      "- Min RBC: 2.77 million cells/µL\n",
      "- Min MCH: 25.7 pg\n",
      "- Min MCHC: 30.7 g/dL\n",
      "- Min MCV: 83 fL\n",
      "- Min iron: (not provided, but low haemoglobin and haematocrit suggest iron deficiency)\n",
      "- Min reticulocyte count: (not provided, but would be useful for further evaluation)\n",
      "- Alternative differentials to consider: Thalassemia, Chronic disease anaemia, Vitamin B12 deficiency\n",
      "\n",
      "*Liver Dysfunction*\n",
      "- Max ALT: 303 U/L\n",
      "- Max AST: 337 U/L\n",
      "- Max ALP: 503 U/L\n",
      "- Max total bilirubin: 1.5 mg/dL\n",
      "- Min albumin: 3.3 g/dL\n",
      "- Alternative differentials to consider: Hepatitis, Alcoholic liver disease, Non-alcoholic fatty liver disease\n",
      "\n",
      "*Electrolyte Imbalance*\n",
      "- Min calcium: 7.9 mg/dL\n",
      "- Min potassium: 3.3 mmol/L\n",
      "- Min sodium: 136 mmol/L\n",
      "- Max sodium: 142 mmol/L\n",
      "- Min chloride: 101 mmol/L\n",
      "- Max chloride: 106 mmol/L\n",
      "- Alternative differentials to consider: Renal dysfunction, Endocrine disorders, Dehydration\n",
      "\n",
      "*Respiratory Acidosis*\n",
      "- Initial blood gas pH: 7.34\n",
      "- Initial blood gas pCO2: 51 mmHg\n",
      "- Initial blood gas total CO2: 29 mmol/L\n",
      "- Alternative differentials to consider: Chronic obstructive pulmonary disease (COPD), Respiratory muscle fatigue, Central nervous system depression\n",
      "\n",
      "*Right Forearm Edema*\n",
      "- Ultrasound findings: Moderate subcutaneous edema, Moderate to severe intramuscular edema\n",
      "- No focal or drainable fluid collection identified\n",
      "- No subcutaneous gas identified\n",
      "- Alternative differentials to consider: Cellulitis, Deep vein thrombosis, Compartment syndrome\n"
     ]
    }
   ],
   "source": [
    "print(result_df.iloc[765]['GPT-Diagnoses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6d20003",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('GPT4o_diag_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a60643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('GPT4o_diag_result.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c758497",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_followup(query, response, follow_up, model=\"gpt-4-1106-preview\"):\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant who gives reasons for all answers.\"},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "            {\"role\": \"user\", \"content\": follow_up}\n",
    "        ])\n",
    "    return response#.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb9c4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_up_message = \"\"\"Below are the actual diagnoses of the same patient reported by clinicians.\n",
    "Go through the actual diagnoses and cross-check each actual diagnosis with \\\n",
    "the initial list of diagnoses you provided answer the following two questions:\n",
    "\n",
    "Question 1: Is this actual diagnosis a new disease, not directly related to any of the diagnoses or alternatives you suggested \\\n",
    "in your initial list? If an actual diagnosis is a complication of, a more specific version of, or falls under a broader \\\n",
    "category of a diagnosis / alternative you initially listed, it should not be considered a new disease. If an actual diagnosis \\\n",
    "affects the same organ as a diagnosis / alternative you initially listed, but it has a different onset and progression \\\n",
    "(for example, the actual diagnosis is chronic but you initially listed the acute disease), then your answer should be 'No'. \\\n",
    "If an actual diagnosis is caused by the same pathogen as a diagnosis in your initial list, the answer should also be 'No'. \\\n",
    "If an actual diagnosis is not a medical diagnosis, your answer should be 'No'.\n",
    "\n",
    "If your answer to Question 1 was 'No', put N/A as answer for Question 2 and skip to the Example below. \n",
    "\n",
    "Question 2: Would it be possible to directly infer this actual diagnosis from the patient data provided in the initial query? \n",
    "If yes, support with facts: quote exact numbers or text from the initial query. \n",
    "If no, in case the data contradicts the diagnosis, quote the data and say why it does not support the diagnosis. \\\n",
    "Otherwise, please specify what additional data would have been helpful to establish this diagnosis.\n",
    "\n",
    "Example:\n",
    "If the patient data is:\n",
    "\"Blood report: min potassium: 3.1, avg hemoglobin: 14.5, max sodium: 139, avg wbc: 13.9\n",
    "Blood gas report: ph: 7.2\n",
    "Imaging report: patient with polysubstance abuse, lungs look normal\"\n",
    "\n",
    "and your initial list in your previous response contained the following suggested diagnoses:\n",
    "*Acidosis*\n",
    "- ph of 7.2\n",
    "- Alternative differentials to consider: respiratory acidosis, metabolic acidosis, mixed acid-base disorder\n",
    "\n",
    "*Polysubstance abuse*\n",
    "- The imaging report mentions \"patient with polysubstance abuse\"\n",
    "- Alternative differentials to consider: alcohol abuse, drug abuse, signs of withdrawal'\n",
    "\n",
    "*Leukocytosis*\n",
    "- avg wbc of 13.9 \n",
    "- Alternative differentials to consider: infection, inflammatory condition, myeloproliferative disorder\n",
    "\n",
    "and actual diagnoses are:\n",
    "D1: Poisoning by cocaine\n",
    "D2: Hypokalemia\n",
    "D3: Hypernatremia\n",
    "D4: Severe sepsis\n",
    "\n",
    "Then your answer should be:\n",
    "D1: Poisoning by cocaine\n",
    "Question 1: No, this is similar to diagnosis *Polysubstance abuse*\n",
    "Question 2: N/A\n",
    "\n",
    "D2: Hypokalemia\n",
    "Question 1: Yes\n",
    "Question 2: Yes, the blood report mentions \"min potassium: 3.1\"\n",
    "\n",
    "D3: Hypernatremia\n",
    "Question 1: Yes\n",
    "Question 2: No, the blood report mentions \"max sodium: 139\", but only sodium levels above 145 mmol/L indicate hypernatremia, \\\n",
    "hence the data does not support hypernatremia.\n",
    "\n",
    "D4: Severe sepsis\n",
    "Question 1: Yes\n",
    "Question 2: No, additional data such as fever, increased heart rate, increased respiratory rate, positive blood cultures, or evidence of organ dysfunction would have been helpful to establish this diagnosis. \"\n",
    "\n",
    "Before finalizing your answer check if you haven't missed noticing any diagnoses from your initial list that are related to \\\n",
    "any of the actual diagnoses you answered the two questions for! If you did, modify the answers to the questions accordingly!\n",
    "\n",
    "Actual diagnoses:\\n\"\"\"\n",
    "\n",
    "async def get_evaluation(queries, responses, follow_ups):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = []\n",
    "    for query, response, follow_up in zip(queries, responses, follow_ups):\n",
    "        tasks.append(get_followup(query, response, follow_up))\n",
    "    all_data = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c57a6632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [33:55<00:00, 50.90s/it]\n"
     ]
    }
   ],
   "source": [
    "query_per_call = 25\n",
    "repeat = []\n",
    "for i in tqdm(range(0,1000,query_per_call)):\n",
    "    try:\n",
    "        idx_from = i\n",
    "        idx_to = i + query_per_call\n",
    "        queries = [prompt_no_example +  patient_data + result_df.iloc[i]['GPT_input'] for i in range(idx_from,idx_to)]\n",
    "        responses = result_df.iloc[idx_from:idx_to,:]['GPT-Diagnoses']\n",
    "        follow_ups = [follow_up_message + result_df.iloc[i]['diagnoses'].replace('\\n', '\\nD').replace('1:', 'D1:', 1) for i in range(idx_from,idx_to)]\n",
    "        result = asyncio.run(get_evaluation(queries, responses, follow_ups))\n",
    "        contents = [result[i].choices[0].message.content for i in range(query_per_call)]\n",
    "        hadm_ids = [result_df.index[i] for i in range(idx_from,idx_to)]\n",
    "        result_df.loc[hadm_ids, 'GPT-Eval'] = contents\n",
    "    except Exception as e: \n",
    "        print('Error happened at iteration i: ' + str(i))\n",
    "        repeat.append(i)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11dd8970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:40<00:00, 40.23s/it]\n"
     ]
    }
   ],
   "source": [
    "query_per_call = 1\n",
    "for i in tqdm([360]):\n",
    "    try:\n",
    "        idx_from = i\n",
    "        idx_to = i + query_per_call\n",
    "        queries = [prompt_no_example +  patient_data + result_df.iloc[i]['GPT_input'] for i in range(idx_from,idx_to)]\n",
    "        responses = result_df.iloc[idx_from:idx_to,:]['GPT-Diagnoses']\n",
    "        follow_ups = [follow_up_message + result_df.iloc[i]['diagnoses'].replace('\\n', '\\nD').replace('1:', 'D1:', 1) for i in range(idx_from,idx_to)]\n",
    "        result = asyncio.run(get_evaluation(queries, responses, follow_ups))\n",
    "        contents = [result[i].choices[0].message.content for i in range(query_per_call)]\n",
    "        hadm_ids = [result_df.index[i] for i in range(idx_from,idx_to)]\n",
    "        result_df.loc[hadm_ids, 'GPT-Eval'] = contents\n",
    "    except Exception as e: \n",
    "        print('Error happened at iteration i: ' + str(i))\n",
    "        repeat.append(i)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e2712c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(text, index):\n",
    "    mistakes = []\n",
    "    hits = []\n",
    "    excluded = [] #not a medical diagnosis\n",
    "    noninferables = []\n",
    "    current = 1\n",
    "    total_adjust = 0\n",
    "    #for conditions that GPT-4 grouped together - still doesn't capture issue with hadmid 23707730\n",
    "    from_nums = []\n",
    "    to_nums = []\n",
    "    grouped = re.findall(r'\\n\\d+-\\d+:', text)\n",
    "    if len(grouped) > 0:\n",
    "        #print(\"Grouping found!\")\n",
    "        #print(\"At index: \")\n",
    "        #print(index)\n",
    "        for elem in grouped:\n",
    "            from_nums.append(str(int(elem.split('-')[0]))) #str(int()) for safety\n",
    "            to_nums.append(str(int(elem.split('-')[1].strip(':'))))\n",
    "    while 1:\n",
    "        try:\n",
    "            if current == 1:\n",
    "                number = str(current)\n",
    "                #sometimes GPT-4 adds words like Diagnosis or Actual diagnosis, and we want to capture that\n",
    "                pre_word = text.split(number, 1)[0]\n",
    "            #for conditions that GPT-4 grouped together\n",
    "            elif str(current) in from_nums:\n",
    "                idx = from_nums.index(str(current))\n",
    "                number = grouped[idx]\n",
    "                total_adjust += int(to_nums[idx]) - current\n",
    "                current = int(to_nums[idx])\n",
    "            else:\n",
    "                number = '\\n' + pre_word + str(current)\n",
    "            nextOne = '\\n' + pre_word + str(current+1)\n",
    "            if text.split(number, 1)[1].split('Question 1: ', 1)[1][:2] == 'No':\n",
    "                if 'not a medical diagnosis' in text.split(number, 1)[1].split('Question 1: ', 1)[1].split('Question 2: ', 1)[0].split(nextOne, 1)[0]:\n",
    "                    print(index)\n",
    "                    print(text.split(number, 1)[1].split('Question 1: ', 1)[0])\n",
    "                    excluded.append(str(current))\n",
    "                else:\n",
    "                    hits.append(str(current))\n",
    "            elif text.split(number, 1)[1].split('Question 2: ', 1)[1][:3] == 'Yes':\n",
    "                mistakes.append(str(current))\n",
    "            elif text.split(number, 1)[1].split('Question 2: ', 1)[1][:2] == 'No':\n",
    "                noninferables.append(str(current))\n",
    "            else:\n",
    "                print(\"Unable to parse text when looking at diagnosis number: \")\n",
    "                print(current)\n",
    "                print(\"At index: \")\n",
    "                print(index)\n",
    "        except:\n",
    "            #print('Diagnosis number not found in text: ')\n",
    "            #print(current)\n",
    "            total = current - 1 - total_adjust\n",
    "            break\n",
    "        current += 1\n",
    "    return pd.Series([len(hits), len(noninferables), len(mistakes), len(excluded), '; '.join(hits), '; '.join(noninferables), '; '.join(mistakes), '; '.join(excluded), total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06def1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      ": Unspecified fall\n",
      "\n",
      "14\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "47\n",
      ": Other place in hospital as the place of occurrence of the external cause\n",
      "\n",
      "58\n",
      ": Long-term (current) use of aspirin\n",
      "\n",
      "78\n",
      ": Awaiting organ transplant status\n",
      "\n",
      "88\n",
      ": Examination of participant in clinical trial\n",
      "\n",
      "94\n",
      ": 31 weeks gestation of pregnancy\n",
      "\n",
      "102\n",
      ": Anxiety state, unspecified\n",
      "\n",
      "105\n",
      ": Do not resuscitate status\n",
      "\n",
      "105\n",
      ": Encounter for palliative care\n",
      "\n",
      "141\n",
      ": Presence of cardiac pacemaker\n",
      "\n",
      "141\n",
      ": Presence of other heart-valve replacement\n",
      "\n",
      "158\n",
      ": Unspecified place in other non-institutional residence as the place of occurrence of the external cause\n",
      "\n",
      "182\n",
      ": Personal history of tobacco use\n",
      "\n",
      "211\n",
      ": Accidental fall from ladder\n",
      "\n",
      "221\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "230\n",
      ": Other motor vehicle traffic accident involving collision with motor vehicle injuring passenger in motor vehicle other than motorcycle\n",
      "\n",
      "239\n",
      ": Do not resuscitate\n",
      "\n",
      "261\n",
      ": Dysthymic disorder\n",
      "\n",
      "287\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "290\n",
      ": Accidents occurring in unspecified place\n",
      "\n",
      "291\n",
      ": Posttraumatic stress disorder\n",
      "\n",
      "302\n",
      ": Personal history of tobacco use\n",
      "\n",
      "309\n",
      ": Gastrostomy status\n",
      "\n",
      "321\n",
      ": Personal history of tobacco use\n",
      "\n",
      "332\n",
      ": Physical restraint status\n",
      "\n",
      "332\n",
      ": Encounter for examination for normal comparison and control in clinical research program\n",
      "\n",
      "355\n",
      ": Personal history of nicotine dependence\n",
      "\n",
      "355\n",
      ": Personal history of peptic ulcer disease\n",
      "\n",
      "355\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "368\n",
      ": Other fall from one level to another, initial encounter\n",
      "\n",
      "368\n",
      ": Unspecified place in unspecified non-institutional (private) residence as the place of occurrence of the external cause\n",
      "\n",
      "369\n",
      ": Do not resuscitate\n",
      "\n",
      "370\n",
      ": Personal history of tobacco use\n",
      "\n",
      "386\n",
      ": Unspecified place in unspecified non-institutional (private) residence as the place of occurrence of the external cause\n",
      "\n",
      "438\n",
      ": Fall from other slipping, tripping, or stumbling\n",
      "\n",
      "444\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "444\n",
      ": Encounter for examination for normal comparison and control in clinical research program\n",
      "\n",
      "449\n",
      ": Body Mass Index 26.0-26.9, adult\n",
      "\n",
      "459\n",
      ": Unspecified place in unspecified non-institutional (private) residence as the place of occurrence of the external cause\n",
      "\n",
      "482\n",
      ": Do not resuscitate status\n",
      "\n",
      "491\n",
      ": Personal history of noncompliance with medical treatment, presenting hazards to health\n",
      "\n",
      "491\n",
      ": Unemployment\n",
      "\n",
      "509\n",
      ": Operating room of hospital as the place of occurrence of the external cause\n",
      "\n",
      "509\n",
      ": Encounter for examination for normal comparison and control in clinical research program\n",
      "\n",
      "528\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "529\n",
      ": Family history of ischemic heart disease\n",
      "\n",
      "539\n",
      ": Unspecified place in hospital as the place of occurrence of the external cause\n",
      "\n",
      "546\n",
      ": Do not resuscitate status\n",
      "\n",
      "564\n",
      ": Examination of participant in clinical trial\n",
      "\n",
      "575\n",
      ": Do not resuscitate status\n",
      "\n",
      "576\n",
      ": Other place in hospital as the place of occurrence of the external cause\n",
      "\n",
      "602\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "607\n",
      ": Laparoscopic surgical procedure converted to open procedure\n",
      "\n",
      "623\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "627\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "Unable to parse text when looking at diagnosis number: \n",
      "1\n",
      "At index: \n",
      "628\n",
      "631\n",
      ": Unspecified place in unspecified non-institutional (private) residence as the place of occurrence of the external cause\n",
      "\n",
      "631\n",
      ": Patient room in hospital as the place of occurrence of the external cause\n",
      "\n",
      "640\n",
      ": Bipolar I disorder, most recent episode (or current) depressed, unspecified\n",
      "\n",
      "640\n",
      ": Unspecified nonpsychotic mental disorder\n",
      "\n",
      "654\n",
      ": Do not resuscitate\n",
      "\n",
      "682\n",
      ": Patient room in hospital as the place of occurrence of the external cause\n",
      "\n",
      "698\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "722\n",
      ": Do not resuscitate\n",
      "\n",
      "726\n",
      ": Unspecified place in unspecified non-institutional (private) residence as the place of occurrence of the external cause\n",
      "\n",
      "726\n",
      ": Physical restraint status\n",
      "\n",
      "741\n",
      ": Procedure not carried out for other reasons\n",
      "\n",
      "741\n",
      ": Accidents occurring in residential institution\n",
      "\n",
      "741\n",
      ": Tobacco use disorder\n",
      "\n",
      "770\n",
      ": Do not resuscitate\n",
      "\n",
      "770\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "783\n",
      ": Accidents occurring in residential institution\n",
      "\n",
      "844\n",
      ": Lack of housing\n",
      "\n",
      "863\n",
      ": Encounter for palliative care\n",
      "\n",
      "884\n",
      ": Do not resuscitate status\n",
      "\n",
      "901\n",
      ": Other specified places as the place of occurrence of the external cause\n",
      "\n",
      "905\n",
      ": Encounter for palliative care\n",
      "\n",
      "911\n",
      ": Motor vehicle traffic accident of unspecified nature injuring unspecified person\n",
      "\n",
      "919\n",
      ": Encounter for examination for normal comparison and control in clinical research program\n",
      "\n",
      "921\n",
      ": Encounter for therapeutic drug monitoring\n",
      "\n",
      "935\n",
      ": Do not resuscitate status\n",
      "\n",
      "935\n",
      ": Encounter for palliative care\n",
      "\n",
      "937\n",
      ": Unspecified place or not applicable\n",
      "\n",
      "947\n",
      ": Personal history of nicotine dependence\n",
      "\n",
      "952\n",
      ": Alcohol dependence, uncomplicated\n",
      "\n",
      "952\n",
      ": Do not resuscitate\n",
      "\n",
      "952\n",
      ": Tobacco use\n",
      "\n",
      "954\n",
      ": Encounter for palliative care\n",
      "\n",
      "954\n",
      ": Percutaneous transluminal coronary angioplasty status\n",
      "\n",
      "958\n",
      ": Motor vehicle traffic accident due to loss of control, without collision on the highway, injuring motorcyclist\n",
      "\n",
      "970\n",
      ": Examination of participant in clinical trial\n",
      "\n",
      "974\n",
      ": Do not resuscitate status\n",
      "\n",
      "974\n",
      ": Encounter for palliative care\n",
      "\n",
      "974\n",
      ": Physical restraints status\n",
      "\n",
      "0.9967398775555874\n",
      "0.9976328248290374\n"
     ]
    }
   ],
   "source": [
    "analyzed_df = result_df.apply(lambda row: analyze_results(row['GPT-Eval'], row.name),1)\n",
    "analyzed_df.columns = ['no_hits', 'no_noninferables', 'no_mistakes', 'no_excluded', 'hits', 'noninferables', 'mistakes', 'excluded', 'total_ICD_diagnoses']\n",
    "analyzed_df['error'] = analyzed_df['no_mistakes'] / (analyzed_df['no_hits'] + analyzed_df['no_mistakes'])\n",
    "analyzed_df['sensitivity'] = 1-analyzed_df['error']\n",
    "print(analyzed_df['sensitivity'].mean())\n",
    "print(1-(analyzed_df['no_mistakes'].sum() / (analyzed_df['no_hits'].sum() + analyzed_df['no_mistakes'].sum())))\n",
    "\n",
    "results = pd.concat([result_df, analyzed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e63b0037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['num_real_diag'] = results['diagnoses'].str.split('\\n').apply(len)\n",
    "results[results['total_ICD_diagnoses'] != results['num_real_diag']].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cd8f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regenerating results where analyzed diagnoses were not equal to true number of diagnoses\n",
    "\n",
    "follow_up_message = \"\"\"Below are the actual diagnoses of the same patient reported by clinicians.\n",
    "Go through the actual diagnoses and cross-check each actual diagnosis with \\\n",
    "the initial list of diagnoses you provided and answer both of the following two questions:\n",
    "\n",
    "Question 1: Is this actual diagnosis a new disease, not directly related to any of the diagnoses you suggested \\\n",
    "in your initial list? If an actual diagnosis is a complication of, a more specific version of, or falls under a broader \\\n",
    "category of a diagnosis you initially listed, it should not be considered a new disease. If an actual diagnosis \\\n",
    "affects the same organ as a diagnosis you initially listed, but it has a different onset and progression \\\n",
    "(for example, the actual diagnosis is chronic but you initially listed the acute disease), then your answer should be 'No'. \\\n",
    "If an actual diagnosis is caused by the same pathogen as a diagnosis in your initial list, the answer should also be 'No'. \\\n",
    "If an actual diagnosis is not a medical diagnosis, your answer should be 'No'.\n",
    "\n",
    "Only if your answer to Question 1 was 'No', put N/A as answer for Question 2 and skip to the Example below. \n",
    "\n",
    "Question 2: Would it be possible to directly infer this actual diagnosis from the patient data provided in the initial query? \n",
    "If yes, support with facts: quote exact numbers or text from the initial query. \n",
    "If no, in case the data contradicts the diagnosis, quote the data and say why it does not support the diagnosis. \\\n",
    "Otherwise, please specify what additional data would have been helpful to establish this diagnosis.\n",
    "\n",
    "Example:\n",
    "If the patient data is:\n",
    "\"Blood report: min potassium: 3.1, avg hemoglobin: 14.5, max sodium: 139, avg wbc: 13.9\n",
    "Blood gas report: ph: 7.2\n",
    "Imaging report: patient with polysubstance abuse, lungs look normal\"\n",
    "\n",
    "and your initial list in your previous response contained the following suggested diagnoses:\n",
    "*Acidosis*\n",
    "- ph of 7.2\n",
    "- Alternative differentials to consider: respiratory acidosis, metabolic acidosis, mixed acid-base disorder\n",
    "\n",
    "*Polysubstance abuse*\n",
    "- The imaging report mentions \"patient with polysubstance abuse\"\n",
    "- Alternative differentials to consider: alcohol abuse, drug abuse, signs of withdrawal'\n",
    "\n",
    "*Leukocytosis*\n",
    "- avg wbc of 13.9 \n",
    "- Alternative differentials to consider: infection, inflammatory condition, myeloproliferative disorder\n",
    "\n",
    "and actual diagnoses are:\n",
    "D1: Poisoning by cocaine\n",
    "D2: Hypokalemia\n",
    "D3: Hypernatremia\n",
    "D4: Severe sepsis\n",
    "\n",
    "Then your answer should be:\n",
    "D1: Poisoning by cocaine\n",
    "Question 1: No, this is similar to diagnosis *Polysubstance abuse*\n",
    "Question 2: N/A\n",
    "\n",
    "D2: Hypokalemia\n",
    "Question 1: Yes\n",
    "Question 2: Yes, the blood report mentions \"min potassium: 3.1\"\n",
    "\n",
    "D3: Hypernatremia\n",
    "Question 1: Yes\n",
    "Question 2: No, the blood report mentions \"max sodium: 139\", but only sodium levels above 145 mmol/L indicate hypernatremia, \\\n",
    "hence the data does not support hypernatremia.\n",
    "\n",
    "D4: Severe sepsis\n",
    "Question 1: Yes\n",
    "Question 2: No, additional data such as fever, increased heart rate, increased respiratory rate, positive blood cultures, or evidence of organ dysfunction would have been helpful to establish this diagnosis. \"\n",
    "\n",
    "Before finalizing your answer check if you haven't missed noticing any diagnoses from your initial list that are related to \\\n",
    "any of the actual diagnoses you answered the two questions for! If you did, modify the answers to the questions accordingly!\n",
    "\n",
    "Actual diagnoses:\\n\"\"\"\n",
    "\n",
    "regenerate = results[results['total_ICD_diagnoses'] != results['num_real_diag']].index.tolist()\n",
    "query_per_call = len(regenerate)\n",
    "async def regenerate_evaluation(regenerate):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = []\n",
    "    queries = [prompt_no_example +  patient_data] + result_df.loc[regenerate, 'GPT_input'].values\n",
    "    responses = result_df.loc[regenerate, 'GPT-Diagnoses'].values\n",
    "    follow_ups = [follow_up_message + result_df.loc[reg, 'diagnoses'].replace('\\n', '\\nD').replace('1:', 'D1:', 1) for reg in regenerate]\n",
    "    for query, response, follow_up in zip(queries, responses, follow_ups):\n",
    "        tasks.append(get_followup(query, response, follow_up))\n",
    "    all_data = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    return all_data\n",
    "\n",
    "try:\n",
    "    result = asyncio.run(regenerate_evaluation(regenerate))\n",
    "    contents = [result[i].choices[0].message.content for i in range(query_per_call)]\n",
    "    result_df.loc[regenerate, 'GPT-Eval'] = contents\n",
    "except Exception as e: \n",
    "    print('Error happened at iteration i: ' + str(i))\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dd9a3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def debug_analyze(text):\n",
    "#     mistakes = []\n",
    "#     hits = []\n",
    "#     excluded = [] #not a medical diagnosis\n",
    "#     noninferables = []\n",
    "#     current = 1\n",
    "#     total_adjust = 0\n",
    "#     from_nums = []\n",
    "#     to_nums = []\n",
    "#     grouped = re.findall(r'\\n\\d+-\\d+:', text)\n",
    "#     if len(grouped) > 0:\n",
    "#         #print(\"Grouping found!\")\n",
    "#         #print(\"At index: \")\n",
    "#         #print(index)\n",
    "#         for elem in grouped:\n",
    "#             from_nums.append(str(int(elem.split('-')[0]))) #str(int()) for safety\n",
    "#             to_nums.append(str(int(elem.split('-')[1].strip(':'))))\n",
    "#     while 1:\n",
    "#         try:\n",
    "#             if current == 1:\n",
    "#                 number = str(current)\n",
    "#                 #sometimes GPT-4 adds words like Diagnosis or Actual diagnosis, and we want to capture that\n",
    "#                 pre_word = text.split(number, 1)[0]\n",
    "#             #for conditions that GPT-4 grouped together\n",
    "#             elif str(current) in from_nums:\n",
    "#                 idx = from_nums.index(str(current))\n",
    "#                 number = grouped[idx]\n",
    "#                 total_adjust += int(to_nums[idx]) - current\n",
    "#                 current = int(to_nums[idx])\n",
    "#             else:\n",
    "#                 number = '\\n' + pre_word + str(current)\n",
    "#             nextOne = '\\n' + pre_word + str(current+1)\n",
    "#             if text.split(number, 1)[1].split('Question 1: ', 1)[1][:2] == 'No':\n",
    "#                 if 'not a medical diagnosis' in text.split(number, 1)[1].split('Question 1: ', 1)[1].split('Question 2: ', 1)[0].split(nextOne, 1)[0]:\n",
    "#                     print(text.split(number, 1)[1].split('Question 1: ', 1)[0])\n",
    "#                     print(text.split(number, 1)[1].split('Question 1: ', 1)[1].split('Question 2: ', 1)[0].split(nextOne, 1)[0])\n",
    "#                     excluded.append(str(current))\n",
    "#                 else:\n",
    "#                     hits.append(str(current))\n",
    "#             elif text.split(number, 1)[1].split('Question 2: ', 1)[1][:3] == 'Yes':\n",
    "#                 mistakes.append(str(current))\n",
    "#             elif text.split(number, 1)[1].split('Question 2: ', 1)[1][:2] == 'No':\n",
    "#                 noninferables.append(str(current))\n",
    "#             else:\n",
    "#                 print(\"Unable to parse text when looking at diagnosis number: \")\n",
    "#                 print(current)\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             print('Diagnosis number not found in text: ')\n",
    "#             print(current)\n",
    "#             total = current - 1 - total_adjust\n",
    "#             break\n",
    "#         current += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140086a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47071636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47cb48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('results_GPT4o_ProdRAG_TurboEval.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f6d8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('result_df_GPT4o_ProdRAG_TurboEval.csv')\n",
    "\n",
    "results = pd.concat([result_df, analyzed_df], axis=1)\n",
    "\n",
    "results.to_csv('results_GPT4o_ProdRAG_TurboEval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf43b918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>diagnoses</th>\n",
       "      <th>GPT_input</th>\n",
       "      <th>GPT-Diagnoses</th>\n",
       "      <th>GPT-Eval</th>\n",
       "      <th>no_hits</th>\n",
       "      <th>no_noninferables</th>\n",
       "      <th>no_mistakes</th>\n",
       "      <th>no_excluded</th>\n",
       "      <th>hits</th>\n",
       "      <th>noninferables</th>\n",
       "      <th>mistakes</th>\n",
       "      <th>excluded</th>\n",
       "      <th>total_ICD_diagnoses</th>\n",
       "      <th>error</th>\n",
       "      <th>sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>23088928</td>\n",
       "      <td>1:Nonrheumatic aortic (valve) stenosis\\n2:Unsp...</td>\n",
       "      <td>Blood report: \\nThe patient stayed in the hosp...</td>\n",
       "      <td>*Anaemia*\\n- Min haemoglobin: 9.4 g/dL\\n- Min ...</td>\n",
       "      <td>D1: Nonrheumatic aortic (valve) stenosis\\nQues...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1; 3</td>\n",
       "      <td>2; 4; 5; 7; 8; 9; 11; 12; 13; 14</td>\n",
       "      <td>6; 10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id                                          diagnoses  \\\n",
       "569  23088928  1:Nonrheumatic aortic (valve) stenosis\\n2:Unsp...   \n",
       "\n",
       "                                             GPT_input  \\\n",
       "569  Blood report: \\nThe patient stayed in the hosp...   \n",
       "\n",
       "                                         GPT-Diagnoses  \\\n",
       "569  *Anaemia*\\n- Min haemoglobin: 9.4 g/dL\\n- Min ...   \n",
       "\n",
       "                                              GPT-Eval  no_hits  \\\n",
       "569  D1: Nonrheumatic aortic (valve) stenosis\\nQues...        2   \n",
       "\n",
       "     no_noninferables  no_mistakes  no_excluded  hits  \\\n",
       "569                10            2            0  1; 3   \n",
       "\n",
       "                        noninferables mistakes excluded  total_ICD_diagnoses  \\\n",
       "569  2; 4; 5; 7; 8; 9; 11; 12; 13; 14    6; 10      NaN                   14   \n",
       "\n",
       "     error  sensitivity  \n",
       "569    0.5          0.5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results.no_mistakes>=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edf6a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.no_mistakes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ee6cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7604"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['no_hits'].sum() + results['no_mistakes'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3699006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7586"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['no_hits'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c213bb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6704"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['no_noninferables'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9026ec3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['no_excluded'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0151fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14402"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['no_hits'].sum() + results['no_mistakes'].sum() + results['no_noninferables'].sum() + results['no_excluded'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a89753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14403"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['diagnoses'].str.split('\\n').apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d4fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['num_real_diag'] = results['diagnoses'].str.split('\\n').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d3ae9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['total_ICD_diagnoses'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7669b5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>diagnoses</th>\n",
       "      <th>GPT_input</th>\n",
       "      <th>GPT-Diagnoses</th>\n",
       "      <th>GPT-Eval</th>\n",
       "      <th>no_hits</th>\n",
       "      <th>no_noninferables</th>\n",
       "      <th>no_mistakes</th>\n",
       "      <th>no_excluded</th>\n",
       "      <th>hits</th>\n",
       "      <th>noninferables</th>\n",
       "      <th>mistakes</th>\n",
       "      <th>excluded</th>\n",
       "      <th>total_ICD_diagnoses</th>\n",
       "      <th>error</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>num_real_diag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hadm_id, diagnoses, GPT_input, GPT-Diagnoses, GPT-Eval, no_hits, no_noninferables, no_mistakes, no_excluded, hits, noninferables, mistakes, excluded, total_ICD_diagnoses, error, sensitivity, num_real_diag]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['total_ICD_diagnoses'] != results['num_real_diag']] #this should never happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f024c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identified_diagnoses(text, numbers):\n",
    "    hit_names = []\n",
    "    if numbers == '' or numbers == 'nan':\n",
    "        return hit_names\n",
    "    nums = numbers.split(';')\n",
    "    names = text.split('\\n')\n",
    "    try:\n",
    "        for num in nums:\n",
    "            diag = names[int(num.strip())-1]\n",
    "            name = re.sub('[0-9]+:', '', diag, 1)\n",
    "            hit_names.append(name)\n",
    "    except ValueError:\n",
    "        print(nums)\n",
    "    return hit_names\n",
    "\n",
    "results['hits'] = results['hits'].astype('str')\n",
    "results['hit_names'] = results.apply(lambda row: get_identified_diagnoses(row['diagnoses'], row['hits']),1)\n",
    "\n",
    "results['mistakes'] = results['mistakes'].astype('str')\n",
    "results['mistake_names'] = results.apply(lambda row: get_identified_diagnoses(row['diagnoses'], row['mistakes']),1)\n",
    "\n",
    "results['noninferables'] = results['noninferables'].astype('str')\n",
    "results['noninferable_names'] = results.apply(lambda row: get_identified_diagnoses(row['diagnoses'], row['noninferables']),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ebb2fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7586"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['hit_names'].apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a61c2be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1733"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.array(results['hit_names'].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae18e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hits = []\n",
    "for i in results['hit_names'].values:\n",
    "    for hits in i:\n",
    "        all_hits.append(hits)\n",
    "        \n",
    "all_mistakes = []\n",
    "for i in results['mistake_names'].values:\n",
    "    for mistakes in i:\n",
    "        all_mistakes.append(mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3ec408d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acute kidney failure, unspecified                                                                                         218\n",
       "Acidosis                                                                                                                  129\n",
       "Congestive heart failure, unspecified                                                                                     127\n",
       "Anemia, unspecified                                                                                                       108\n",
       "Diabetes mellitus without mention of complication, type II or unspecified type, not stated as uncontrolled                105\n",
       "Acute posthemorrhagic anemia                                                                                               99\n",
       "Chronic kidney disease, unspecified                                                                                        98\n",
       "Unspecified essential hypertension                                                                                         92\n",
       "Coronary atherosclerosis of native coronary artery                                                                         91\n",
       "Hypertensive chronic kidney disease, unspecified, with chronic kidney disease stage I through stage IV, or unspecified     81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_hits).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab878b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes mellitus without mention of complication, type II or unspecified type, not stated as uncontrolled    4\n",
       "Type 2 diabetes mellitus without complications                                                                4\n",
       "Hypoxemia                                                                                                     2\n",
       "Anemia, unspecified                                                                                           1\n",
       "Bradycardia, unspecified                                                                                      1\n",
       "Essential (primary) hypertension                                                                              1\n",
       "Hypopotassemia                                                                                                1\n",
       "Hypotension, unspecified                                                                                      1\n",
       "Prediabetes                                                                                                   1\n",
       "Tachycardia, unspecified                                                                                      1\n",
       "Type 2 diabetes mellitus with diabetic neuropathy, unspecified                                                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_mistakes).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04182d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       14.403000\n",
       "std         6.812121\n",
       "min         1.000000\n",
       "25%         9.000000\n",
       "50%        14.000000\n",
       "75%        19.000000\n",
       "max        39.000000\n",
       "Name: num_real_diag, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['num_real_diag'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4574e578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['num_real_diag'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6f151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5976ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548aa85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
